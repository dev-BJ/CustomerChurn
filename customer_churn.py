# -*- coding: utf-8 -*-
"""customer_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nOGxjNMG5pT93mSvAU0u1wtVp_b4BtJO
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
# Import VotingClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score
from time import time
import matplotlib.pyplot as plt
from datetime import datetime

print(f'Start @ {datetime.now()}')
# Load the dataset
data = pd.read_csv('./train.csv')

# data

# print(data.info())

# print(data.isna().sum())

# Drop unnecessary columns
# data_cleaned = data.drop(['id', 'CustomerId', 'Surname'], axis='columns')
data_cleaned = data.drop(['id', 'CustomerId', 'Surname'], axis=1)

#data_cleaned.head(5)
# data_cleaned.Geography.value_counts()

# One-hot encoding for 'Geography' and label encoding for 'Gender'
data_cleaned = pd.get_dummies(data_cleaned, columns=['Geography'], drop_first=True)
#data_cleaned['Gender'] = data_cleaned['Gender'].map({'Male': 1, 'Female': 0})
data_cleaned['Gender'] = data_cleaned['Gender'].apply(lambda x : 1 if x == 'Male' else 0)

# Separate features (X) and target (y)
X = data_cleaned.drop('Exited', axis=1)  # Features
y = data_cleaned['Exited']               # Target

# Reduce the data size (e.g., keep only 50% of the data)
sample_size = int(0.5 * len(X))
X = X.sample(n=sample_size, random_state=42)
y = y[X.index]


# Standardize numerical features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
# print(X_scaled)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Initialize classifiers
classifiers = {
    'Logistic Regression': LogisticRegression(),
    'SVM': SVC(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier()
}

# Dictionary to store the accuracy results
results = {}

clf_start=time()
print(f'CLF start @ {datetime.now()}')
# Train and evaluate the classifiers
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)  # Train the model
    y_pred = clf.predict(X_test)  # Make predictions on the test set
    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy
    results[name] = accuracy  # Store the results
clf_end=time()
print(f'CLF end @ {datetime.now()}')

# Print the accuracy results
print("Classifier Performance:")
for clf_name, accuracy in results.items():
    print(f"{clf_name}: {accuracy:.4f}")
print(f"Time used: {clf_end-clf_start}s")

#Classification takes ~7min

y_plt=[acc for acc in results.values()]
x_plt=[name for name in results.keys()]

# Initialize the base classifiers
log_clf = LogisticRegression()
svm_clf = SVC(probability=True)
rf_clf = RandomForestClassifier()
gb_clf = GradientBoostingClassifier()
knn_clf = KNeighborsClassifier()

# Create a VotingClassifier with all base classifiers
voting_clf = VotingClassifier(
    estimators=[
        ('log_clf', log_clf),
        ('svm_clf', svm_clf),
        ('rf_clf', rf_clf),
        ('gb_clf', gb_clf),
        ('knn_clf', knn_clf)
    ],
    voting='soft'
)

print(" " * 40)

v_clf_start=time()
print(f'Voting start @ {datetime.now()}')
# Train VotingClassifier
voting_clf.fit(X_train, y_train)

# Make predictions
y_pred_voting = voting_clf.predict(X_test)

print(f'Voting end @ {datetime.now()}')
# Voting takes ~45min

x_data=pd.DataFrame({'Exited':y_pred_voting})['Exited'].value_counts().sort_index()
y_name=['No(0)','Yes(1)']

# Evaluate VotingClassifier accuracy
voting_accuracy = accuracy_score(y_test, y_pred_voting)
print(f"Voting Classifier Accuracy: {voting_accuracy:.4f}")
v_clf_end=time()
print(f"Voting time: {v_clf_end-v_clf_start}s")
print(f'End @ {datetime.now()}')

plt.figure(figsize=(8,6))

plt.subplot(211)
plt.bar(x_plt,y_plt,color=['red','green'],width=0.5)
plt.xlabel('Output')
plt.ylabel('Models')
plt.title('Classifiers')

plt.subplot(212)
plt.bar(y_name,x_data,color=['red','green','blue'],width=0.5)
plt.xlabel('Churn output')
plt.ylabel('Total Churn')
plt.title('Voting')

plt.tight_layout()

plt.savefig('OutputImage/figure.png')
plt.show()